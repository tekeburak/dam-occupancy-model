{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IBB_.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Q4L9se6w9IqX",
        "JMQdP7ao-7LR",
        "ZdkSqFms-_6z",
        "3yV8bXR9gohu",
        "OCKRXl3niUqJ",
        "xQhFoQyZjviX"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4L9se6w9IqX"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Cjbai3RSHW"
      },
      "source": [
        "This is IBB water reservation predict application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqIhNrLFRPrt"
      },
      "source": [
        "from google.colab import drive\r\n",
        "import pandas as pd\r\n",
        "from pandas import read_csv, DataFrame\r\n",
        "from math import sqrt\r\n",
        "\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMQdP7ao-7LR"
      },
      "source": [
        "# This only needs to be done once in a notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WeVWdkSVfQD"
      },
      "source": [
        "# Import PyDrive and associated libraries.\r\n",
        "# This only needs to be done once in a notebook.\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n",
        "\r\n",
        "# Authenticate and create the PyDrive client.\r\n",
        "# This only needs to be done once in a notebook.\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)\r\n",
        "\r\n",
        "# Create & upload a text file.\r\n",
        "uploaded = drive.CreateFile({'title': 'dam_occupancy.csv'})\r\n",
        "uploaded.SetContentString('Sample upload file content')\r\n",
        "uploaded.Upload()\r\n",
        "print('Uploaded file with ID {}'.format(uploaded.get('id')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdkSqFms-_6z"
      },
      "source": [
        "# This part loading data to workspace and splitting dataset to test and validation files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bnm1nV1sXz87"
      },
      "source": [
        "series = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dam_occupancy.csv', header=0)\r\n",
        "series['DATE'] =  pd.to_datetime(series['DATE'])\r\n",
        "series = series.set_index('DATE')\r\n",
        "series = series['GENERAL_DAM_OCCUPANCY_RATE']\r\n",
        "\r\n",
        "split_point = len(series) - 816\r\n",
        "dataset, validation = series[0:split_point], series[split_point:]\r\n",
        "\r\n",
        "print('Dataset %d, Validation %d' % (len(dataset), len(validation)))\r\n",
        "dataset.to_csv('dataset.csv', header=True)\r\n",
        "validation.to_csv('validation.csv', header=True)\r\n",
        "print(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yV8bXR9gohu"
      },
      "source": [
        "# this part for the plotting data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "id-Dj5veb48I"
      },
      "source": [
        "# test oluşumlarını çizdirir. verilerin dagılımını gormek için \r\n",
        "X = dataset # can use series or validation to see their plot as well\r\n",
        "print(X)\r\n",
        "train_size = int(len(X) * 0.66)\r\n",
        "train, test = X[0:train_size], X[train_size:len(X)]\r\n",
        "print('Observations: %d' % (len(X)))\r\n",
        "print('Training Observations: %d' % (len(train)))\r\n",
        "print('Testing Observations: %d' % (len(test)))\r\n",
        "train.plot(y = \"GENERAL_DAM_OCCUPANCY_RATE\",style = 'o',figsize = (15,2))\r\n",
        "test.plot(y = \"GENERAL_DAM_OCCUPANCY_RATE\",style = 'o',figsize = (15,2))\r\n",
        "pyplot.show()\r\n",
        "# this part i wanted to see the cycles in year\r\n",
        "pyplot.figure()\r\n",
        "pyplot.plot(X[:360])\r\n",
        "pyplot.show()\r\n",
        "pyplot.figure()\r\n",
        "pyplot.plot(X[360:720])\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCKRXl3niUqJ"
      },
      "source": [
        "# calculate repeated train-test splits of time series data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA6LkdG0fQ8C"
      },
      "source": [
        "# calculate repeated train-test splits of time series data\r\n",
        "# this part for setting split size and plotting that splitted dataset\r\n",
        "from pandas import read_csv\r\n",
        "from sklearn.model_selection import TimeSeriesSplit\r\n",
        "from matplotlib import pyplot\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "X = series\r\n",
        "splits = TimeSeriesSplit(n_splits=3)# burada bolumlendirilme sayısı ayarlanıyor.\r\n",
        "pyplot.figure(1)\r\n",
        "index = 1\r\n",
        "for train_index, test_index in splits.split(X):\r\n",
        "    train = X[train_index]\r\n",
        "    test = X[test_index]\r\n",
        "    print('Observations: %d' % (len(train) + len(test)))\r\n",
        "    print('Training Observations: %d' % (len(train)))\r\n",
        "    print('Testing Observations: %d' % (len(test)))\r\n",
        "    pyplot.subplot(350 + index)\r\n",
        "    train.plot(y = \"GENERAL_DAM_OCCUPANCY_RATE\",style = 'o',figsize = (30,4))\r\n",
        "    test.plot(y = \"GENERAL_DAM_OCCUPANCY_RATE\",style = 'o',figsize = (30,4))\r\n",
        "    index += 1\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7ZFDPVxid4Q"
      },
      "source": [
        "# lag plot of time series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQnufJL2CLus"
      },
      "source": [
        "# lag plot of time series\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from pandas.plotting import lag_plot\r\n",
        "\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0,parse_dates=True, squeeze=True)\r\n",
        "lag_plot(series)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgiAfkzWIo7y"
      },
      "source": [
        "# correlation of lag=1\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import DataFrame\r\n",
        "from pandas import concat\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0,parse_dates=True, squeeze=True)\r\n",
        "values = DataFrame(series.values)\r\n",
        "dataframe = concat([values.shift(1), values], axis=1)\r\n",
        "dataframe.columns = ['t', 't+1']\r\n",
        "result = dataframe.corr()\r\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOip13zOI7DS"
      },
      "source": [
        "# autocorrelation plot of time series\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from pandas.plotting import autocorrelation_plot\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0,parse_dates=True, squeeze=True)\r\n",
        "autocorrelation_plot(series)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoP9ADrFJNIJ"
      },
      "source": [
        "# autocorrelation plot of time series\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from statsmodels.graphics.tsaplots import plot_acf\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0,parse_dates=True, squeeze=True)\r\n",
        "plot_acf(series, lags=451)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwIvd1e7rQwH"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJz_LR9orTf4"
      },
      "source": [
        "# load and plot dataset\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import datetime\r\n",
        "from matplotlib import pyplot\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# summarize first few rows\r\n",
        "print(series.head())\r\n",
        "# line plot\r\n",
        "series.plot()\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBdci_wOrlEX"
      },
      "source": [
        "# autocorrelation plot of time series\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import datetime\r\n",
        "from matplotlib import pyplot\r\n",
        "from pandas.plotting import autocorrelation_plot\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# autocorrelation plot\r\n",
        "autocorrelation_plot(series)\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow5sI_Jaqvoi"
      },
      "source": [
        "# fit an ARIMA model and plot residual errors\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import datetime\r\n",
        "from pandas import DataFrame\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from matplotlib import pyplot\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# fit model\r\n",
        "model = ARIMA(series, order=(5,1,0),)\r\n",
        "model_fit = model.fit(disp=0)\r\n",
        "# summary of fit model\r\n",
        "print(model_fit.summary())\r\n",
        "# line plot of residuals\r\n",
        "residuals = DataFrame(model_fit.resid)\r\n",
        "residuals.plot()\r\n",
        "pyplot.show()\r\n",
        "# density plot of residuals\r\n",
        "residuals.plot(kind='kde')\r\n",
        "pyplot.show()\r\n",
        "# summary stats of residuals\r\n",
        "print(residuals.describe())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEgyWn0qrxNm"
      },
      "source": [
        "# evaluate an ARIMA model using a walk-forward validation\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import datetime\r\n",
        "from matplotlib import pyplot\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# split into train and test sets\r\n",
        "X = series.values\r\n",
        "size = int(len(X) * 0.66)\r\n",
        "train, test = X[0:size], X[size:len(X)]\r\n",
        "history = [x for x in train]\r\n",
        "predictions = list()\r\n",
        "# walk-forward validation\r\n",
        "for t in range(len(test)):\r\n",
        "\tmodel = ARIMA(history, order=(5,1,0))\r\n",
        "\tmodel_fit = model.fit(disp=0)\r\n",
        "\toutput = model_fit.forecast()\r\n",
        "\tyhat = output[0]\r\n",
        "\tpredictions.append(yhat)\r\n",
        "\tobs = test[t]\r\n",
        "\thistory.append(obs)\r\n",
        "\tprint('predicted=%f, expected=%f' % (yhat, obs))\r\n",
        "# evaluate forecasts\r\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "print('Test RMSE: %.3f' % rmse)\r\n",
        "# plot forecasts against actual outcomes\r\n",
        "pyplot.plot(test)\r\n",
        "pyplot.plot(predictions, color='red')\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmL5ri2cvKTt"
      },
      "source": [
        "print(test)\r\n",
        "print(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Z3E9fGqtXi"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjiNJnakKskd"
      },
      "source": [
        "# evaluate a persistence model\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import DataFrame\r\n",
        "from pandas import concat\r\n",
        "from matplotlib import pyplot\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# create lagged dataset\r\n",
        "values = DataFrame(series.values)\r\n",
        "dataframe = concat([values.shift(1), values], axis=1)\r\n",
        "dataframe.columns = ['t', 't+1']\r\n",
        "# split into train and test sets\r\n",
        "X = dataframe.values\r\n",
        "train, test = X[1:len(X)-1000], X[len(X)-1000:]\r\n",
        "train_X, train_y = train[:,0], train[:,1]\r\n",
        "test_X, test_y = test[:,0], test[:,1]\r\n",
        "# persistence model\r\n",
        "def model_persistence(x):\r\n",
        "\treturn x\r\n",
        "# walk-forward validation\r\n",
        "predictions = list()\r\n",
        "for x in test_X:\r\n",
        "\tyhat = model_persistence(x)\r\n",
        "\tpredictions.append(yhat)\r\n",
        "rmse = sqrt(mean_squared_error(test_y, predictions))\r\n",
        "print('Test RMSE: %.3f' % rmse)\r\n",
        "# plot predictions vs expected\r\n",
        "pyplot.plot(test_y)\r\n",
        "pyplot.plot(predictions, color='red')\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RkkDlHPqpvJ"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7_SQQ3BYkDD"
      },
      "source": [
        "# create and evaluate an updated autoregressive model\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from statsmodels.tsa.ar_model import AR\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# split dataset\r\n",
        "X = series.values\r\n",
        "train, test = X[1:len(X)-10], X[len(X)-10:]\r\n",
        "# train autoregression\r\n",
        "model = AR(train)\r\n",
        "model_fit = model.fit()\r\n",
        "window = model_fit.k_ar\r\n",
        "coef = model_fit.params\r\n",
        "# walk forward over time steps in test\r\n",
        "history = train[len(train)-window:]\r\n",
        "history = [history[i] for i in range(len(history))]\r\n",
        "predictions = list()\r\n",
        "for t in range(len(test)):\r\n",
        "\tlength = len(history)\r\n",
        "\tlag = [history[i] for i in range(length-window,length)]\r\n",
        "\tyhat = coef[0]\r\n",
        "\tfor d in range(window):\r\n",
        "\t\tyhat += coef[d+1] * lag[window-d-1]\r\n",
        "\tobs = test[t]\r\n",
        "\tpredictions.append(yhat)\r\n",
        "\thistory.append(obs)\r\n",
        "\tprint('predicted=%f, expected=%f' % (yhat, obs))\r\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "print('Test RMSE: %.3f' % rmse)\r\n",
        "# plot\r\n",
        "pyplot.plot(test)\r\n",
        "pyplot.plot(predictions, color='red')\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7D-rGwJZDAX"
      },
      "source": [
        "# create and evaluate a static autoregressive model\r\n",
        "from pandas import read_csv\r\n",
        "from matplotlib import pyplot\r\n",
        "from statsmodels.tsa.ar_model import AR\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# split dataset\r\n",
        "X = series.values\r\n",
        "train, test = X[1:len(X)-10], X[len(X)-1000:]\r\n",
        "# train autoregression\r\n",
        "model = AR(train)\r\n",
        "model_fit = model.fit()\r\n",
        "print('Lag: %s' % model_fit.k_ar)\r\n",
        "print('Coefficients: %s' % model_fit.params)\r\n",
        "# make predictions\r\n",
        "predictions = model_fit.predict(start=len(train), end=len(train)+len(test)-1, dynamic=False)\r\n",
        "for i in range(len(predictions)):\r\n",
        "\tprint('predicted=%f, expected=%f' % (predictions[i], test[i]))\r\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "print('Test RMSE: %.3f' % rmse)\r\n",
        "# plot results\r\n",
        "pyplot.plot(test)\r\n",
        "pyplot.plot(predictions, color='red')\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmTfIrO2qmZ9"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDgbRo4GjxFk"
      },
      "source": [
        "# correct forecasts with a model of forecast residual errors\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import DataFrame\r\n",
        "from pandas import concat\r\n",
        "from statsmodels.tsa.ar_model import AR\r\n",
        "from matplotlib import pyplot\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "# load data\r\n",
        "series = read_csv('dataset.csv', header=0, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# create lagged dataset\r\n",
        "values = DataFrame(series.values)\r\n",
        "dataframe = concat([values.shift(1), values], axis=1)\r\n",
        "dataframe.columns = ['t', 't+1']\r\n",
        "# split into train and test sets\r\n",
        "X = dataframe.values\r\n",
        "train_size = int(len(X) * 0.66)\r\n",
        "train, test = X[1:train_size], X[train_size:]\r\n",
        "train_X, train_y = train[:,0], train[:,1]\r\n",
        "test_X, test_y = test[:,0], test[:,1]\r\n",
        "# persistence model on training set\r\n",
        "train_pred = [x for x in train_X]\r\n",
        "# calculate residuals\r\n",
        "train_resid = [train_y[i]-train_pred[i] for i in range(len(train_pred))]\r\n",
        "# model the training set residuals\r\n",
        "model = AR(train_resid)\r\n",
        "model_fit = model.fit()\r\n",
        "window = model_fit.k_ar\r\n",
        "coef = model_fit.params\r\n",
        "# walk forward over time steps in test\r\n",
        "history = train_resid[len(train_resid)-window:]\r\n",
        "history = [history[i] for i in range(len(history))]\r\n",
        "predictions = list()\r\n",
        "for t in range(len(test_y)):\r\n",
        "\t# persistence\r\n",
        "\tyhat = test_X[t]\r\n",
        "\terror = test_y[t] - yhat\r\n",
        "\t# predict error\r\n",
        "\tlength = len(history)\r\n",
        "\tlag = [history[i] for i in range(length-window,length)]\r\n",
        "\tpred_error = coef[0]\r\n",
        "\tfor d in range(window):\r\n",
        "\t\tpred_error += coef[d+1] * lag[window-d-1]\r\n",
        "\t# correct the prediction\r\n",
        "\tyhat = yhat + pred_error\r\n",
        "\tpredictions.append(yhat)\r\n",
        "\thistory.append(error)\r\n",
        "\tprint('predicted=%f, expected=%f' % (yhat, test_y[t]))\r\n",
        "# error\r\n",
        "rmse = sqrt(mean_squared_error(test_y, predictions))\r\n",
        "print('Test RMSE: %.3f' % rmse)\r\n",
        "# plot predicted error\r\n",
        "pyplot.plot(test_y)\r\n",
        "pyplot.plot(predictions, color='red')\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQhFoQyZjviX"
      },
      "source": [
        "# Yeni Bölüm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wp85vcV-YQJR"
      },
      "source": [
        "# load data\r\n",
        "series = DataFrame(read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True))\r\n",
        "# prepare data\r\n",
        "X = series.values[:,0]\r\n",
        "#X=series\r\n",
        "X = X.astype('float32')\r\n",
        "train_size = int(len(X) * 0.60)\r\n",
        "train, test = X[0:train_size], X[train_size:]\r\n",
        "\r\n",
        "# walk-forward validation\r\n",
        "history = [x for x in train]\r\n",
        "print(history)\r\n",
        "predictions = list()\r\n",
        "for i in range(len(test)):\r\n",
        "    # predict\r\n",
        "    yhat = history[-1]\r\n",
        "    predictions.append(yhat)\r\n",
        "    # observation\r\n",
        "    obs = test[i]\r\n",
        "    #obs = test.values[i,0]\r\n",
        "    history.append(obs)\r\n",
        "    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\r\n",
        "# report performance\r\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "pyplot.plot(predictions)\r\n",
        "pyplot.plot(test)\r\n",
        "pyplot.show()\r\n",
        "print('RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvhkRHPcYYNK"
      },
      "source": [
        "# evaluate manually configured ARIMA model\r\n",
        "from pandas import read_csv\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S10DhqLpZB7F"
      },
      "source": [
        "\r\n",
        "# create a differenced series\r\n",
        "def difference(dataset, interval=1):\r\n",
        "    diff = list()\r\n",
        "    for i in range(interval, len(dataset)):\r\n",
        "        value = dataset[i] - dataset[i - interval]\r\n",
        "        diff.append(value)\r\n",
        "    return diff\r\n",
        "\r\n",
        "\r\n",
        "# invert differenced value\r\n",
        "def inverse_difference(history, yhat, interval=1):\r\n",
        "    return yhat + history[-interval]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ig_1B5RZFm5"
      },
      "source": [
        "# load data\r\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# prepare data\r\n",
        "X = series.values\r\n",
        "X = X.astype('float32')\r\n",
        "train_size = int(len(X) * 0.50)\r\n",
        "train, test = X[0:train_size], X[train_size:]\r\n",
        "# walk-forward validation\r\n",
        "history = [x for x in train]\r\n",
        "predictions = list()\r\n",
        "for i in range(len(test)):\r\n",
        "    # difference data\r\n",
        "    months_in_year = 12\r\n",
        "    diff = difference(history, months_in_year)\r\n",
        "    # predict\r\n",
        "    model = ARIMA(diff, order=(1, 0, 4))\r\n",
        "    model_fit = model.fit(trend='nc', disp=0)\r\n",
        "    yhat = model_fit.forecast()[0]\r\n",
        "    yhat = inverse_difference(history, yhat, months_in_year)\r\n",
        "    predictions.append(yhat)\r\n",
        "    # observation\r\n",
        "    obs = test[i]\r\n",
        "    history.append(obs)\r\n",
        "    print('>Predicted=%.3f, Expected=%.3f' % (yhat, obs))\r\n",
        "# report performance\r\n",
        "rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "print('RMSE: %.3f' % rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAGc4ioEvTUZ"
      },
      "source": [
        "# BU Kısımda  bulunabiliecek en iyi ARIMA p,d,q degerlerini buluyoruz.\r\n",
        "\r\n",
        "# grid search ARIMA parameters for time series\r\n",
        "import warnings\r\n",
        "from pandas import read_csv\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from math import sqrt\r\n",
        "import numpy\r\n",
        "# create a differenced series\r\n",
        "def difference(dataset, interval=1):\r\n",
        "    diff = list()\r\n",
        "    for i in range(interval, len(dataset)):\r\n",
        "      value = dataset[i] - dataset[i - interval]\r\n",
        "      diff.append(value)\r\n",
        "    return numpy.array(diff)\r\n",
        "\r\n",
        "# invert differenced value\r\n",
        "def inverse_difference(history, yhat, interval=1):\r\n",
        "    return yhat + history[-interval]\r\n",
        "# evaluate an ARIMA model for a given order (p,d,q) and return RMSE\r\n",
        "def evaluate_arima_model(X, arima_order):\r\n",
        "    # prepare training dataset\r\n",
        "    X = X.astype('float32')\r\n",
        "    train_size = int(len(X) * 0.50)\r\n",
        "    train, test = X[0:train_size], X[train_size:]\r\n",
        "    history = [x for x in train]\r\n",
        "    # make predictions\r\n",
        "    predictions = list()\r\n",
        "    for t in range(len(test)):\r\n",
        "        # difference data\r\n",
        "        months_in_year = 12\r\n",
        "        diff = difference(history, months_in_year)\r\n",
        "        model = ARIMA(diff, order=arima_order)\r\n",
        "        model_fit = model.fit(trend='nc', disp=0)\r\n",
        "        yhat = model_fit.forecast()[0]\r\n",
        "        yhat = inverse_difference(history, yhat, months_in_year)\r\n",
        "        predictions.append(yhat)\r\n",
        "        history.append(test[t])\r\n",
        "    # calculate out of sample error\r\n",
        "    rmse = sqrt(mean_squared_error(test, predictions))\r\n",
        "    return rmse\r\n",
        "# evaluate combinations of p, d and q values for an ARIMA model\r\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\r\n",
        "    dataset = dataset.astype('float32')\r\n",
        "    best_score, best_cfg = float(\"inf\"), None\r\n",
        "    for p in p_values:\r\n",
        "      for d in d_values:\r\n",
        "        for q in q_values:\r\n",
        "          order = (p,d,q)\r\n",
        "          try:\r\n",
        "              rmse = evaluate_arima_model(dataset, order)\r\n",
        "              if rmse < best_score:\r\n",
        "                 best_score, best_cfg = rmse, order\r\n",
        "              print('ARIMA%s RMSE=%.3f' % (order,rmse))\r\n",
        "          except:\r\n",
        "            continue\r\n",
        "          print('test q bitti q =%.3f '%q)  \r\n",
        "    print('Best ARIMA%s RMSE=%.3f' % (best_cfg, best_score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ERzGi_ObUgW"
      },
      "source": [
        "# load dataset\r\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# evaluate parameters\r\n",
        "p_values = range(0, 6)\r\n",
        "d_values = range(0, 3)\r\n",
        "q_values = range(0, 6)\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "evaluate_models(series.values, p_values, d_values, q_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1emGLBIB9yez"
      },
      "source": [
        "# summarize ARIMA forecast residuals i will use best of ARIMA (1,0,4)\r\n",
        "from pandas import read_csv\r\n",
        "from pandas import DataFrame\r\n",
        "from statsmodels.tsa.arima_model import ARIMA\r\n",
        "from matplotlib import pyplot\r\n",
        "# create a differenced series\r\n",
        "def difference(dataset, interval=1):\r\n",
        "    diff = list()\r\n",
        "    for i in range(interval, len(dataset)):\r\n",
        "      value = dataset[i] - dataset[i - interval]\r\n",
        "      diff.append(value)\r\n",
        "    return diff\r\n",
        "# invert differenced value\r\n",
        "def inverse_difference(history, yhat, interval=1):\r\n",
        "    return yhat + history[-interval]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUqMfvl8yvcM"
      },
      "source": [
        "# load data\r\n",
        "series = read_csv('dataset.csv', header=None, index_col=0, parse_dates=True, squeeze=True)\r\n",
        "# prepare data\r\n",
        "X = series.values\r\n",
        "X = X.astype('float32')\r\n",
        "train_size = int(len(X) * 0.50)\r\n",
        "train, test = X[0:train_size], X[train_size:]\r\n",
        "# walk-forward validation\r\n",
        "history = [x for x in train]\r\n",
        "predictions = list()\r\n",
        "for i in range(len(test)):\r\n",
        "    # difference data\r\n",
        "    months_in_year = 12\r\n",
        "    diff = difference(history, months_in_year)\r\n",
        "    # predict\r\n",
        "    model = ARIMA(diff, order=(1,0,4))\r\n",
        "    model_fit = model.fit(trend='nc', disp=0)\r\n",
        "    yhat = model_fit.forecast()[0]\r\n",
        "    yhat = inverse_difference(history, yhat, months_in_year)\r\n",
        "    predictions.append(yhat)\r\n",
        "    # observation\r\n",
        "    obs = test[i]\r\n",
        "    history.append(obs)\r\n",
        "# errors\r\n",
        "residuals = [test[i]-predictions[i] for i in range(len(test))]\r\n",
        "residuals = DataFrame(residuals)\r\n",
        "print(residuals.describe())\r\n",
        "# plot\r\n",
        "pyplot.figure()\r\n",
        "pyplot.subplot(211)\r\n",
        "residuals.hist(ax=pyplot.gca())\r\n",
        "pyplot.subplot(212)\r\n",
        "residuals.plot(kind='kde', ax=pyplot.gca())\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}